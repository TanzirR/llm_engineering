{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94d093fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b40ae811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "MODEL = 'gpt-4o-mini'\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fc1e993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent a Website that we have scraped, now with links\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            self.text = \"\"\n",
    "        links = [link.get('href') for link in soup.find_all('a')]\n",
    "        self.links = [link for link in links if link]\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a612f9b",
   "metadata": {},
   "source": [
    "##### First step: Have GPT-4o-mini figure out which links are relevant\n",
    "##### Use a call to gpt-4o-mini to read the links on a webpage, and respond in structured JSON.\n",
    "It should decide which links are relevant, and replace relative links such as \"/about\" with \"https://company.com/about\".\n",
    "We will use \"one shot prompting\" in which we provide an example of how it should respond in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ec66a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
    "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
    "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\" \\\n",
    "\"Do NOT make up any links that are not available on the website.\\n\"\n",
    "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
    "link_system_prompt += \"\"\"\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfbe6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(link_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "407d42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_links_user_prompt(website):\n",
    "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
    "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
    "Do not include Terms of Service, Privacy, email links.\\n\"\n",
    "    user_prompt += \"Links (some might be relative links):\\n\"\n",
    "    user_prompt += \"\\n\".join(website.links)\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "841dcbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
    "      ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b4c21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "huggingface = Website(\"https://huggingface.co\")\n",
    "huggingface.links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30785699",
   "metadata": {},
   "source": [
    "##### Second step: Make the brochure\n",
    "\n",
    "Assemble all the details into another gpt4-o prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "07621078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_details(url):\n",
    "    result = \"Landing page:\\n\"\n",
    "    result += Website(url).get_contents()\n",
    "    links = get_links(url)\n",
    "    print(\"Found links:\", links)\n",
    "    for link in links[\"links\"]:\n",
    "        result += f\"\\n\\n{link['type']}\\n\"\n",
    "        result += Website(link[\"url\"]).get_contents()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1a5c7495",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt_english = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\\\n",
    "Include details of any relevant information you have about the company. DO NOT make up any information that is not present in the website.\" \\\n",
    "\"Respond in Markdown\"\n",
    "\n",
    "system_prompt_bengali = \"\"\"\n",
    "\"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\\\n",
    "Include details of any relevant information you have about the company. DO NOT make up any information that is not present in the website. \\\n",
    "Respond in Bengali in Markdown. \\\n",
    "Keep any URLs in the brochure in their original text.\"\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89d72985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brochure_user_prompt(company_name, url):\n",
    "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
    "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
    "    user_prompt += get_all_details(url)\n",
    "    user_prompt = user_prompt[:1_000] # Truncate if more than 1,000 characters\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40cbdc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url, language):\n",
    "    if language == \"English\":\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt_english},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ]\n",
    "    elif language == \"Bengali\":\n",
    "        message = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt_bengali},\n",
    "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
    "        ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=message,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\" \n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9840869",
   "metadata": {},
   "source": [
    "### Gradio UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a148c720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d7555fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1763918a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7881\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7881/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/gradio/queueing.py\", line 667, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/gradio/route_utils.py\", line 349, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 2274, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/gradio/blocks.py\", line 1793, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 760, in async_iteration\n",
      "    return await anext(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 751, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 2476, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/anyio/_backends/_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 734, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/gradio/utils.py\", line 898, in gen_wrapper\n",
      "    response = next(iterator)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_31955/3982251012.py\", line 5, in create_brochure\n",
      "    {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
      "                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_31955/906043373.py\", line 4, in get_brochure_user_prompt\n",
      "    user_prompt += get_all_details(url)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_31955/1726772739.py\", line 4, in get_all_details\n",
      "    links = get_links(url)\n",
      "            ^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_31955/1638324738.py\", line 3, in get_links\n",
      "    response = openai.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1147, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 968, in request\n",
      "    request = self._build_request(options, retries_taken=retries_taken)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/openai/_base_client.py\", line 547, in _build_request\n",
      "    return self._client.build_request(  # pyright: ignore[reportUnknownMemberType]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/httpx/_client.py\", line 378, in build_request\n",
      "    return Request(\n",
      "           ^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/httpx/_models.py\", line 408, in __init__\n",
      "    headers, stream = encode_request(\n",
      "                      ^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 216, in encode_request\n",
      "    return encode_json(json)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/python/llm_projects/.venv/lib/python3.12/site-packages/httpx/_content.py\", line 177, in encode_json\n",
      "    body = json_dumps(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/__init__.py\", line 238, in dumps\n",
      "    **kw).encode(obj)\n",
      "          ^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 200, in encode\n",
      "    chunks = self.iterencode(o, _one_shot=True)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 258, in iterencode\n",
      "    return _iterencode(o, 0)\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/json/encoder.py\", line 180, in default\n",
      "    raise TypeError(f'Object of type {o.__class__.__name__} '\n",
      "TypeError: Object of type coroutine is not JSON serializable\n"
     ]
    }
   ],
   "source": [
    "gr.Interface(\n",
    "    fn=create_brochure, \n",
    "    inputs= [\n",
    "                gr.Textbox(label=\"Company Name\"), \n",
    "                gr.Textbox(label=\"Company URL\"),\n",
    "                gr.Dropdown(label=\"Output Language\", choices=[\"English\", \"Bengali\"])\n",
    "             ], \n",
    "    outputs=[gr.Markdown(label=\"Brochure\")],\n",
    "    flagging_mode=\"never\", \n",
    "    js = force_dark_mode,\n",
    "    title=\"AI Brochure Generator\",\n",
    ").launch(share=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
